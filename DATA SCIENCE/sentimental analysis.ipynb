{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+tg1TVSadgsHfevZ9nYWQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Sentimental Analysis NLP"],"metadata":{"id":"rfnCTuZ3YipT"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUc_TU0mYeML","executionInfo":{"status":"ok","timestamp":1671621182262,"user_tz":-330,"elapsed":3758,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"21543d8b-9bbb-4beb-88f9-d914efb0cb45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"]}],"source":["!pip install nltk"]},{"cell_type":"markdown","source":["Importing Libraries"],"metadata":{"id":"pr6Gp3_PYw8w"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd \n","import re #REgular expression\n","import nltk\n","import matplotlib.pyplot as plt\n","\n","\n","from nltk.corpus import stopwords\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n"],"metadata":{"id":"OG3CyPvxY0rJ","executionInfo":{"status":"ok","timestamp":1671623602960,"user_tz":-330,"elapsed":397,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Load DAtasetset from Local Directory"],"metadata":{"id":"c5FT9LOQbCVc"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"HJEt8eP6bjWY","executionInfo":{"status":"ok","timestamp":1671622090472,"user_tz":-330,"elapsed":115772,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"a166b617-1e08-47e9-c4aa-5d66d02d6a37"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cfcffde4-5e87-48c9-857b-ac8b386e6053\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cfcffde4-5e87-48c9-857b-ac8b386e6053\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving text_emotion.csv to text_emotion.csv\n"]}]},{"cell_type":"markdown","source":["Importing Dataset"],"metadata":{"id":"7TU4pY2McDtm"}},{"cell_type":"code","source":["dataset = pd.read_csv('text_emotion.csv')\n","print(dataset.shape)\n","print(dataset.head(5))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgoSZIlLcGC2","executionInfo":{"status":"ok","timestamp":1671622132396,"user_tz":-330,"elapsed":426,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"407a376d-0ca2-4700-ebbb-41fad2e1ddc8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(40000, 4)\n","     tweet_id   sentiment       author  \\\n","0  1956967341       empty   xoshayzers   \n","1  1956967666     sadness    wannamama   \n","2  1956967696     sadness    coolfunky   \n","3  1956967789  enthusiasm  czareaquino   \n","4  1956968416     neutral    xkilljoyx   \n","\n","                                             content  \n","0  @tiffanylue i know  i was listenin to bad habi...  \n","1  Layin n bed with a headache  ughhhh...waitin o...  \n","2                Funeral ceremony...gloomy friday...  \n","3               wants to hang out with friends SOON!  \n","4  @dannycastillo We want to trade with someone w...  \n"]}]},{"cell_type":"markdown","source":["Segregating Dataset into input & Output"],"metadata":{"id":"qX6zvHkicey7"}},{"cell_type":"code","source":["features = dataset.iloc[:,3].values\n","labels = dataset.iloc[:,1].values\n","print(labels)\n","print(features)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aju3_80icsim","executionInfo":{"status":"ok","timestamp":1671622558129,"user_tz":-330,"elapsed":420,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"e11a7016-9bc0-4c06-aff7-46aa116db9d0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['empty' 'sadness' 'sadness' ... 'love' 'happiness' 'love']\n","['@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =['\n"," 'Layin n bed with a headache  ughhhh...waitin on your call...'\n"," 'Funeral ceremony...gloomy friday...' ...\n"," \"Happy Mother's Day to all the mommies out there, be you woman or man as long as you're 'momma' to someone this is your day!\"\n"," '@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY NEW HIT SINGLES WWW.MYSPACE.COM/IPSOHOT I DEF. WAT U IN THE VIDEO!!'\n"," '@mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla']\n"]}]},{"cell_type":"markdown","source":["Removing the Special Character"],"metadata":{"id":"ucKTH6sHdk82"}},{"cell_type":"code","source":["processed_feature = []\n","\n","for sentence in range(0, len(features)):\n","  #Remove all the special characters\n","  processed_feature = re.sub(r'\\W', '', str(features[sentence]))\n","\n","  #remove all the single character \n","  processed_feature = re.sub(r'\\s+[a-zA-Z]\\s+', '', processed_feature)\n","\n","  #Remove single character from the start \n","  processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', '', processed_feature,str(features[sentence])\n","\n","  #Substituting multiple spaces with single space\n","  processed_feature = re.sub(r'\\s+', '', processed_feature, flags=re.I)\n","\n","  #Removing prefixed 'b'\n","  processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n","\n","\n","  #converting to Lowercase\n","  processed_feature = processed_feature.lower()\n","\n","  processed_feature.append(processed_feature)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"MXgmtyT3dsKN","executionInfo":{"status":"error","timestamp":1671624371993,"user_tz":-330,"elapsed":6,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"4cc10007-fc04-44da-8865-b67e060af794"},"execution_count":27,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-692086454826>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    processed_feature = re.sub(r'\\s+', '', processed_feature, flags=re.I)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","source":["Feature Extraction from text "],"metadata":{"id":"UT_DxUUphO_r"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","vectorizer =TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8,stop_words=stopwords.words('english'))\n","processed_features = vectorizer.fit_transform(processed_features).toarray()\n","print(processed_features)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"yAe0E2pMhTEZ","executionInfo":{"status":"error","timestamp":1671623713518,"user_tz":-330,"elapsed":787,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"3233c51a-7c84-4ba1-aa44-780dd28b9f3c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-0198334d04a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocessed_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'processed_features' is not defined"]}]},{"cell_type":"markdown","source":["Splitting dataset into Train & Test"],"metadata":{"id":"leWstur_la_U"}},{"cell_type":"code","source":["X-train, X_test,y_train,y_test = train_test_split(processed_features,labels, test_size=0.2,random_state=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"FWEonktnlfHc","executionInfo":{"status":"error","timestamp":1671624651411,"user_tz":-330,"elapsed":426,"user":{"displayName":"Amit Rathore","userId":"10768912529632415788"}},"outputId":"8d4c5abf-6c3a-4b87-bbe6-0eed36230191"},"execution_count":29,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-df389774fbc1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    X-train, X_test,y_train,y_test = train_test_split(processed_features,labels, test_size=0.2,random_state=0)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"]}]},{"cell_type":"markdown","source":["Loading Random forest Algorithm"],"metadata":{"id":"CnLI3Fq_mDsw"}},{"cell_type":"code","source":["text_classifier = RandomForestClassifier(n_estimators=200,random_state=0)\n","text_classifier.fit(X_train , y_train)"],"metadata":{"id":"Jdj5P9x0mG17"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Predicting the test data with Trained MOdel"],"metadata":{"id":"pRuW1ZDdmZS4"}},{"cell_type":"code","source":["predictions = text_classifier.predict(X_test)"],"metadata":{"id":"xWYgQOAYmeKU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Score of the model "],"metadata":{"id":"hX7OdvQtmuD0"}},{"cell_type":"code","source":["print(accuracy_score(y_test, predictions))"],"metadata":{"id":"JQteegvcmwDw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Confusion matrix"],"metadata":{"id":"rH4nn61jm2qA"}},{"cell_type":"code","source":["from sklearn import metrics\n","import itertools\n","def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n","\n","  plt.imshow(cm,interpolation='nearest',cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  tick_marks = np.arrange(len(character))\n","  plt.xticks(tick_marks,classes)\n","  plt.yticks(tick_marks,classes)\n","\n","  thresh = cm.max() / 2.accuracy_score\n","  for i,j in itertools.product(range(cm.shape[0],range(cm.shape[1]))):\n","    plt.text(j,i,cm[i,j],horizontalalignment=\"center\",color=\"white\" if cm[i,j] > thresh else \"black\" )\n","             horizontalalignment=\"centre\"\n","             color=\"white\" if cm[i,j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label')           \n","  plt.xlabel('True label')    \n","\n","cm = metrics.confusion_matrix(y_test, predictions,labels=['negative','neutral','positive'])\n","plot_confusion_matrix(cm , classes=['negative','neutral', 'positive'])\n","  \n","\n","\n"],"metadata":{"id":"_tSpPmvBm93a"},"execution_count":null,"outputs":[]}]}